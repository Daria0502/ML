Лабораторная работа №6: Машины опорных векторов Осадиной Дарьи ПМИ 3-1

Исходные данные - данные варианта 17
Набор данных: Default of Credit Card Clients

Источник: https://github.com/ania607/ML/tree/main/data

Зависимая переменная: Y (дефолт по кредитной карте)

Объясняющие переменные: Все, кроме: Y, PAY_4, PAY_5, PAY_6, BILL_AMT4, BILL_AMT5, BILL_AMT6, PAY_AMT1, PAY_AMT2, PAY_AMT3, PAY_AMT4, PAY_AMT5, PAY_AMT6

Ядро генератора: 17

Выполнение задания
Задание 1: Разделение данных
Требование: Данные своего варианта из упражнения 3 разделить на выборку для построения моделей (85%) и отложенные наблюдения (15%). Отложенные наблюдения использовать только для прогноза по лучшей модели.

Выполнение:

Загружен набор данных default_of_credit_card_clients.csv

Исключены столбцы согласно варианту 17

Исходные данные: 30,000 наблюдений × 24 признака

После обработки: 30,000 наблюдений × 11 признаков

Разделение данных: 85% обучающая выборка, 15% отложенная выборка

Использовано стратифицированное разделение для сохранения распределения классов

Результат:

Обучающая выборка: 25,500 наблюдений

Отложенная выборка: 4,500 наблюдений

Распределение классов сохранено: 77.88% класс 0, 22.12% класс 1

Задание 2: Построение пайплайнов моделей
Требование: Построить два пайплайна моделей, каждый из которых включает преобразование объясняющих переменных и модель классификации. Провести настройку параметров каждой модели с помощью сеточного поиска.

Выполнение:

Пайплайн 1: Логистическая регрессия

Преобразование: StandardScaler() + PCA(n_components=2)

Модель: LogisticRegression

Параметры: random_state=17, solver='lbfgs', max_iter=1000

Оценка: Перекрёстная проверка 5-fold

Пайплайн 2: Машина опорных векторов

Преобразование: StandardScaler() + PCA(n_components=2)

Модель: SVC

Настройка параметров: Сеточный поиск

Параметры поиска:

svc__C: [0.01, 0.1, 1.0, 10.0]

svc__kernel: ['linear', 'rbf']

svc__gamma: [0.01, 0.1] (для rbf)

Метод проверки: KFold 3-fold

Результаты сеточного поиска:

Лучшие параметры SVM: {'svc__C': 1.0, 'svc__gamma': 0.1, 'svc__kernel': 'rbf'}

Время выполнения: 104.29 секунд

Количество проверяемых комбинаций: 6

Задание 3: Доведение точности до 96%
Требование: Довести точность Acc лучшего пайплайна (на обучающих данных, с перекрёстной проверкой) до 96% и выше.

Выполнение:

Проведена оптимизация количества компонент PCA

Проверены значения: 5, 10 компонент (максимально возможное: 11)

Использованы лучшие параметры SVM из сеточного поиска

Применена перекрёстная проверка 3-fold для оценки

Результаты оптимизации:

PCA components: 5, Acc: 0.807

PCA components: 10, Acc: 0.820

Лучший результат: 10 компонент, Accuracy: 82.0%

Анализ невозможности достижения 96%:

Фундаментальное ограничение: дисбаланс классов (78%/22%)

Базовый уровень (всегда предсказывать мажоритарный класс): 77.9%

Ограничения варианта: исключены ключевые признаки

Реалистичный максимум для данных условий: 82-85%

Задание 4: Прогноз по лучшей модели
Требование: Сделать прогноз по лучшей модели на отложенные наблюдения и оценить его точность.

Выполнение:

Выбрана лучшая модель: SVM с PCA(10 компонент)

Параметры: C=1.0, gamma=0.1, kernel='rbf'

Выполнен прогноз на отложенной выборке (4,500 наблюдений)

Оценена точность с использованием classification_report

Результаты прогноза:

Общая точность: 80%

Класс 0: precision=0.82, recall=0.95, f1-score=0.88

Класс 1: precision=0.62, recall=0.28, f1-score=0.38

Поддержка: класс 0 - 3505, класс 1 - 995

Сравнение моделей
Точность моделей
Модель	Accuracy
Логистическая регрессия (PCA=2)	79.7%
SVM (PCA=2)	80.5%
SVM (PCA=10) 82.0%
Анализ результатов
Лучшая модель: SVM с 10 компонентами PCA

Увеличение количества компонент PCA улучшило точность на 1.5%

SVM показал себя лучше логистической регрессии

Основная проблема: низкий recall для класса 1 (28%)

Обоснование результатов
Требование достижения точности 96% оказалось невыполнимым в рамках заданных условий варианта 17. Это обусловлено фундаментальными ограничениями данных:

Значительный дисбаланс классов (78%/22%)

Исключение ключевых признаков согласно варианту

Природа задачи прогнозирования дефолта

Максимально достигнутая точность 82% соответствует реалистичным ожиданиям для данной задачи и сравнима с результатами академических исследований на этом наборе данных. Все основные этапы лабораторной работы выполнены в соответствии с требованиями.